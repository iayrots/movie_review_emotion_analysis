{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 번외\n",
    "- tf-idf를 통해 벡터화 해보고 k_fold 를 사용해서 cross_validation 을 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\"\"\"\n",
    "header = 0 은 파일의 첫 번째 줄에 열 이름이 있음을 나타내며 \n",
    "delimiter = \\t 는 필드가 탭으로 구분되는 것을 의미한다.\n",
    "quoting = 3은 쌍따옴표를 무시하도록 한다.\n",
    "\"\"\"\n",
    "# QUOTE_MINIMAL (0), QUOTE_ALL (1), \n",
    "# QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
    "\n",
    "# 레이블인 sentiment 가 있는 학습 데이터\n",
    "train = pd.read_csv('data/labeledTrainData.tsv', \n",
    "                    header=0, delimiter='\\t', quoting=3)\n",
    "# 레이블이 없는 테스트 데이터\n",
    "test = pd.read_csv('data/testData.tsv', \n",
    "                   header=0, delimiter='\\t', quoting=3)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 긍정과 부정 리뷰가 어떻게 들어있는지 카운트 해본다.\n",
    "# 긍정과 부정리뷰가 각각 동일하게 12,500개씩 들어있다.\n",
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# train 데이터에는 sentiment 데이터가 있다.\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      "id        25000 non-null object\n",
      "review    25000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 390.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# test 데이터에는 sentiment가 없으며 이 sentiment를 예측하는 게 이 경진대회의 미션이다.\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리는 tutorial part1~4까지 공통으로 사용되기 때문에 별도의 파이썬 파일로 분리했다.\n",
    "# 그리고 캐글에 있는 코드를 병렬처리하도록 멀티프로세싱 코드를 추가했다.\n",
    "# 하지만 여기에서는 멀티프로세싱 코드만 임포트해서 사용하고 전처리는 태그만 제거해주도록 한다.\n",
    "# 그리고 WordNetLemmatizer로 레마타이징 한다.\n",
    "# 음소표기법(lemmatization)은 tutorial part1에 설명 되어 있다.\n",
    "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    review_text = wordnet_lemmatizer.lemmatize(review_text)\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 ms, sys: 356 ms, total: 477 ms\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "# train 데이터를 전처리 한다.\n",
    "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
    "    train['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 ms, sys: 270 ms, total: 385 ms\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "source": [
    "# train 데이터와 동일하게 test 데이터에 대해서도 전처리 한다.\n",
    "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
    "    test['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"With all this stuff going down at the moment ...\n",
       "1    \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2    \"The film starts with a manager (Nicholas Bell...\n",
       "3    \"It must be assumed that those who praised thi...\n",
       "4    \"Superbly trashy and wondrously unpretentious ...\n",
       "5    \"I dont know why people think this is such a b...\n",
       "6    \"This movie could have been very good, but com...\n",
       "7    \"I watched this video at a friend's house. I'm...\n",
       "8    \"A friend of mine bought this film for £1, and...\n",
       "9    \"This movie is full of references. Like \\\"Mad ...\n",
       "Name: review_clean, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리한 train 데이터 10개만을 불러와서 본다.\n",
    "train['review_clean'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Naturally in a film who's main themes are of ...\n",
       "1    \"This movie is a disaster within a disaster fi...\n",
       "2    \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"Afraid of the Dark left me with the impressio...\n",
       "4    \"A very accurate depiction of small time mob l...\n",
       "5    \"...as valuable as King Tut's tomb! (OK, maybe...\n",
       "6    \"This has to be one of the biggest misfires ev...\n",
       "7    \"This is one of those movies I watched, and wo...\n",
       "8    \"The worst movie i've seen in years (and i've ...\n",
       "9    \"Five medical students (Kevin Bacon, David Lab...\n",
       "Name: review_clean, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리한 test 데이터 10개만을 불러와서 본다.\n",
    "test['review_clean'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train과 X_test에 리뷰 데이터를 담아주고 이 데이터를 TF-IDF를 통해 임베딩(벡터화)해본다. \n",
    "X_train = train['review_clean']\n",
    "X_test = test['review_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "TF(단어 빈도, term frequency)는 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값으로, 이 값이 높을수록 문서에서 중요하다고 생각할 수 있다. 하지만 단어 자체가 문서군 내에서 자주 사용되는 경우, 이것은 그 단어가 흔하게 등장한다는 것을 의미한다. 이것을 DF(문서 빈도, document frequency)라고 하며, 이 값의 역수를 IDF(역문서 빈도, inverse document frequency)라고 한다. TF-IDF는 TF와 IDF를 곱한 값이다.\n",
    "\n",
    "IDF 값은 문서군의 성격에 따라 결정된다. 예를 들어 '원자'라는 낱말은 일반적인 문서들 사이에서는 잘 나오지 않기 때문에 IDF 값이 높아지고 문서의 핵심어가 될 수 있지만, 원자에 대한 문서를 모아놓은 문서군의 경우 이 낱말은 상투어가 되어 각 문서들을 세분화하여 구분할 수 있는 다른 낱말들이 높은 가중치를 얻게 된다.\n",
    "\n",
    "역문서 빈도(IDF)는 한 단어가 문서 집합 전체에서 얼마나 공통적으로 나타나는지를 나타내는 값이다. 전체 문서의 수를 해당 단어를 포함한 문서의 수로 나눈 뒤 로그를 취하여 얻을 수 있다.\n",
    "\n",
    "- 출처 : [TF-IDF - 위키백과](https://ko.wikipedia.org/wiki/TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn 공식문서 : [4.2. Feature extraction — scikit-learn 0.19.1 documentation](http://scikit-learn.org/stable/modules/feature_extraction.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None,\n",
       "        vocabulary={'epithelium', 'Jose', 'cantabank', 'assessorial', 'chronoscope', 'effector', 'beleap', 'Zimmerwaldian', 'amphibrach', 'reeveship', 'procommittee', 'soss', 'theoria', 'atomiferous', 'squibling', 'Mytiliaspis', 'phantasmagoric', 'interosculation', 'redesire', 'nightwear', 'privacy', 'ownho...ishly', 'grawls', 'superformidable', 'bilio', 'behn', 'glow', 'tokenless', 'twinkle', 'phaseometer'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import words\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', \n",
    "                             lowercase = True,\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = 'english',\n",
    "                             min_df = 2, # 토큰이 나타날 최소 문서 개수로 오타나 자주 나오지 않는 특수한 전문용어 제거에 좋다. \n",
    "                             ngram_range=(1, 3),\n",
    "                             vocabulary = set(words.words()), # nltk의 words를 사용하거나 문서 자체의 사전을 만들거나 선택한다. \n",
    "                             max_features = 90000\n",
    "                            )\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfTransformer()\n",
    "\n",
    "- norm='L2' 각 문서의 피처 벡터를 어떻게 벡터 정규화 할지 정한다.\n",
    "    - L2 : 벡터의 각 원소의 제곱의 합이 1이 되도록 만드는 것이고 기본 값\n",
    "    - L1 : 벡터의 각 원소의 절댓값의 합이 1이 되도록 크기를 조절\n",
    "- smooth_idf=False\n",
    "    - 피처를 만들 때 0으로 나오는 항목에 대해 작은 값을 더해서(스무딩을 해서) 피처를 만들지 아니면 그냥 생성할지를 결정\n",
    "- sublinear_tf=False\n",
    "- use_idf=True\n",
    "    - TF-IDF를 사용해 피처를 만들 것인지 아니면 단어 빈도 자체를 사용할 것인지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "       ...('tfidf', TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
       "         use_idf=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
    "])  \n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 182 ms, total: 11.1 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%time X_train_tfidf_vector = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aani',\n",
       " 'Aaron',\n",
       " 'Aaronic',\n",
       " 'Aaronical',\n",
       " 'Aaronite',\n",
       " 'Aaronitic',\n",
       " 'Aaru',\n",
       " 'Ab',\n",
       " 'Ababdeh']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  idf = np.log(float(n_samples) / df) + 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 464 ms, total: 16.1 s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%time X_test_tfidf_vector = pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]] A\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>Aani</th>\n",
       "      <th>Aaron</th>\n",
       "      <th>Aaronic</th>\n",
       "      <th>Aaronical</th>\n",
       "      <th>Aaronite</th>\n",
       "      <th>Aaronitic</th>\n",
       "      <th>Aaru</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Ababdeh</th>\n",
       "      <th>...</th>\n",
       "      <th>zymotechnical</th>\n",
       "      <th>zymotechnics</th>\n",
       "      <th>zymotechny</th>\n",
       "      <th>zymotic</th>\n",
       "      <th>zymotically</th>\n",
       "      <th>zymotize</th>\n",
       "      <th>zymotoxic</th>\n",
       "      <th>zymurgy</th>\n",
       "      <th>zythem</th>\n",
       "      <th>zythum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 235892 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A  Aani  Aaron  Aaronic  Aaronical  Aaronite  Aaronitic  Aaru   Ab  \\\n",
       "0  0.0   0.0    0.0      0.0        0.0       0.0        0.0   0.0  0.0   \n",
       "\n",
       "   Ababdeh   ...    zymotechnical  zymotechnics  zymotechny  zymotic  \\\n",
       "0      0.0   ...              0.0           0.0         0.0      0.0   \n",
       "\n",
       "   zymotically  zymotize  zymotoxic  zymurgy  zythem  zythum  \n",
       "0          0.0       0.0        0.0      0.0     0.0     0.0  \n",
       "\n",
       "[1 rows x 235892 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist = np.sum(X_train_tfidf_vector, axis=0)\n",
    "    \n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)\n",
    "    \n",
    "pd.DataFrame(dist, columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=2018, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤포레스트 분류기를 사용\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators = 100, n_jobs = -1, random_state=2018)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 46s, sys: 2.66 s, total: 4min 49s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%time forest = forest.fit(X_train_tfidf_vector, train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation 교차 검증\n",
    "\n",
    "- 일반화 성능을 측정하기 위해 데이터를 여러 번 반복해서 나누고 여러 모델을 학습한다.\n",
    "- KFold 교차검증\n",
    "    - 데이터를 폴드라 부르는 비슷한 크기의 부분집합(n_splits)으로 나누고 각각의 폴드 정확도를 측정한다.\n",
    "    - 첫 번째 폴드를 test 세트로 사용하고 나머지 폴드를 train 세트로 사용하여 학습한다.\n",
    "    - 나머지 train 세트로 만들어진 세트의 정확도를 첫 번째 폴드로 평가한다.\n",
    "    - 다음은 두 번째 폴드가 test 세트가 되고 나머지 폴드의 train 세트를 두 번째 폴드로 정확도를 측정한다.\n",
    "    - 이 과정을 마지막 폴드까지 반복한다.\n",
    "    - 이렇게 train 세트와 test 세트로 나누는 N개의 분할마다 정확도를 측정하여 평균 값을 낸게 정확도가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 671 ms, sys: 189 ms, total: 860 ms\n",
      "Wall time: 6min 13s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "\n",
    "%time score = np.mean(cross_val_score(\\\n",
    "    forest, X_train_tfidf_vector, \\\n",
    "    train['sentiment'], cv=k_fold, scoring='roc_auc', n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.92068'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_splits=10 일 때 0.92149\n",
    "'{:,.5f}'.format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.94 s, sys: 308 ms, total: 5.25 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%time result = forest.predict(X_test_tfidf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          0\n",
       "3    \"7186_2\"          0\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12688\n",
       "0    12312\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = output['sentiment'].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('data/tutorial_4_tfidf_{0:.5f}.csv'.format(score), index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.31 %\n"
     ]
    }
   ],
   "source": [
    "# 그런데 점수가 너무 낮게 나옴\n",
    "# local 0.92149 일 때, kaggle 0.84392\n",
    "# stop_words = 'english', vocabulary = set(words.words()), smooth_idf = False\n",
    "# kaggle score : 0.84392\n",
    "print(round(470/578*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost: A Scalable Tree Boosting System\n",
    "\n",
    "- 부스팅 알고리즘은 약한 예측모형들을 결합하여 강한 예측모형을 만드는 알고리즘\n",
    "- 배깅과 유사하게 초기 샘플데이터로 다수의 분류기를 만들지만 배깅과 다르게 순차적이다.\n",
    "- 랜덤포레스트의 배깅과는 다르게 이전 트리의 오차를 보완하는 방식으로 순차적으로 트리를 만듦\n",
    "- 결정트리(Decision Tree) 알고리즘의 연장선에 있음\n",
    "- 여러 개의 결정트리를 묶어 강력한 모델을 만드는 앙상블 방법\n",
    "- 분류와 회귀에 사용할 수 있음\n",
    "- 무작위성이 없으며 강력한 사전 가지치기를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_tfidf_vector, label=train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 1.87 s, total: 30.3 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "# 멀티프로세싱은 nthread 였는데 n_jobs로 변경되었다고 한다.\n",
    "# 설치 된 xgboost버전에 따라 파라미터가 다를 수 있으니 \n",
    "# 이 코드를 돌리고 터미널에서 $ top -o cpu 로 CPU자원을 100%넘게 사용하고 있는지 확인해 본다.\n",
    "params = {\n",
    "    'booster': 'gblinear',\n",
    "    'objective': 'multi:softmax',\n",
    "    'eval_metric': 'merror',\n",
    "    'eta' : 0.02,\n",
    "    'lambda': 2.0,\n",
    "    'alpha': 1.0,\n",
    "    'lambda_bias': 6.0,\n",
    "    'num_class': 5,\n",
    "    'n_jobs' : 4,\n",
    "    'silent': 1,\n",
    "}\n",
    "\n",
    "%time booster = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(X_test_tfidf_vector)\n",
    "\n",
    "result = booster.predict(dtest)\n",
    "\n",
    "print(result.shape)\n",
    "result[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          1\n",
       "3    \"7186_2\"          1\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12820\n",
       "0    12180\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = output['sentiment'].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output.to_csv(\"data/tutorial_4_tfidf_xgboost.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle API를 통해 서브미션이 가능하다.\n",
    "- [Kaggle/kaggle-api: Official Kaggle API](https://github.com/Kaggle/kaggle-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading https://files.pythonhosted.org/packages/14/a5/577e46094b1552a316e3ece8d357e1d6a69816effd00110a6dfffc2c7afb/kaggle-1.3.1.tar.gz\n",
      "Requirement already satisfied: urllib3>=1.15 in /Users/macbook/anaconda3/lib/python3.6/site-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: six>=1.10 in /Users/macbook/anaconda3/lib/python3.6/site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in /Users/macbook/anaconda3/lib/python3.6/site-packages (from kaggle) (2018.1.18)\n",
      "Requirement already satisfied: python-dateutil in /Users/macbook/anaconda3/lib/python3.6/site-packages (from kaggle) (2.6.1)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/macbook/Library/Caches/pip/wheels/f4/a4/10/5c73183f0618678e5fbe387d30168f45fb9b441841394a25ab\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unauthorized: you must download an API key from https://www.kaggle.com/<username>/account\r\n",
      "Then put kaggle.json in the folder /Users/macbook/.kaggle\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c word2vec-nlp-tutorial -f data/tutorial_4_tfidf_xgboost.csv -m 'num_boost_round=300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c word2vec-nlp-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.79 %\n"
     ]
    }
   ],
   "source": [
    "# kaggle score 0.86784\n",
    "print(round(282/578*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
